# ğŸ“ Final Year Project  
# Multimodal Stress Detection System  

## ğŸ“– Overview  

This project is my **Final Year Project (FYP)** based on **Multimodal Stress Detection** using both:

- ğŸ™ï¸ Audio Features (MFCC)
- ğŸ¥ Visual Features (Facial-based features)

The system combines audio and visual modalities to perform **binary stress classification (Stress vs Non-Stress)** using deep learning techniques.

---

## ğŸš€ Project Objective  

To build a multimodal machine learning model that:

- Extracts meaningful features from audio and video
- Performs feature fusion
- Detects whether a person is stressed or not
- Provides scalable backend APIs for stress prediction

---

## ğŸ§  Technologies Used  

- Python  
- FastAPI (Backend API)  
- PyTorch / TensorFlow (Deep Learning)  
- Transformer 
- Fully Connected Layers  
- Cross-Modal Fusion  
- Git & GitHub  

---

## ğŸ—ï¸ System Architecture  

1. Audio input â†’ MFCC feature extraction  
2. Video input â†’ Facial feature extraction  
3. Feature-level fusion  
4. Deep Learning Model (LSTM + Dense layers)  
5. Binary Stress Classification  

 
